# BDA Assignment 02 â€” Analyse de Texte avec Apache Spark

**Auteur**: PHAM DANG Son Alain et Imad GAMOUH | **Cours**: Big Data Analytics â€” ESIEE 2025-2026  


---

## ğŸ“‹ DÃ©marrage rapide

### PrÃ©requis
- Python 3.10+, environnement conda
- Apache Spark 4.0.1
- OpenJDK 11+ ou Oracle JDK 11+
- 8 GB de RAM recommandÃ©

### Installation et exÃ©cution

```bash
# 1. Activer l'environnement
conda activate bda-env

# 2. Lancer Jupyter
jupyter lab

# 3. Ouvrir BDA_Assignment02.ipynb et exÃ©cuter sÃ©quentiellement (Sections 1â€“8)

# 4. Surveiller l'interface Spark UI
# Ouvrir http://localhost:4040 pendant l'exÃ©cution
```

---

##  Structure du projet

```
Lab2/assignment/
â”œâ”€â”€ README.md                           â† Vous Ãªtes ici
â”œâ”€â”€ ENV.md                              â† Configuration d'environnement & reproductibilitÃ©
â”œâ”€â”€ BDA_Assignment02.ipynb              â† Notebook principal (exÃ©cutable)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ shakespeare.txt                 (3.6 MB, 122 458 lignes)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ bigram_pairs_top_20.csv
â”‚   â”œâ”€â”€ bigram_stripes_top_20.csv
â”‚   â”œâ”€â”€ pmi_filtered.csv
â”‚   â”œâ”€â”€ index_parquet/                  (Index inversÃ© en Parquet)
â”‚   â”œâ”€â”€ queries_and_results.md
â”‚   â”œâ”€â”€ performance_pairs_vs_stripes.csv
â”‚   â”œâ”€â”€ performance_shuffle_partitions.csv
â”‚   â””â”€â”€ performance_analysis.md
â”‚
â””â”€â”€ proof/
    â”œâ”€â”€ lab_metrics_log.csv             â† MÃ©triques pour toutes les exÃ©cutions
    â”œâ”€â”€ explain_pairs_approach.txt
    â”œâ”€â”€ explain_stripes_approach.txt
    â”œâ”€â”€ plan_pmi.txt
    â”œâ”€â”€ plan_retrieval.txt
    â””â”€â”€ screenshots/                    (Preuves Spark UI)
```

---

##  Vue d'ensemble de l'assignment

### Partie A : FrÃ©quence relative de bigrammes (Pairs vs Stripes)

**TÃ¢che** : Calculer la frÃ©quence relative $f(w_i, w_{i+1}) / f(w_i, *)$ en utilisant deux patterns MapReduce.

**Approches** :
- **Pairs** : Ã‰mettre `((w_i, w_i+1), 1)` et `((w_i, *), 1)` â†’ normaliser ( 3,5 s)
- **Stripes** : Ã‰mettre `(w_i â†’ {w_i+1: count})` â†’ normaliser (84,5 s)

**Gagnant** : **Pairs** (95,9% plus rapide) â€” agrÃ©gation prÃ©coce via `reduceByKey`

**Livrables** :
- `outputs/bigram_pairs_top_20.csv`
- `outputs/bigram_stripes_top_20.csv`
- `proof/explain_pairs_approach.txt`
- `proof/explain_stripes_approach.txt`

---

### Partie B : Information mutuelle ponctuelle (PMI)

**TÃ¢che** : Calculer PMI(x, y) = logâ‚â‚€( P(x,y) / (P(x) Ã— P(y)) ) pour les paires de mots co-apparaissant dans une ligne.

**RÃ¨gles** :
- Premiers 40 tokens par ligne (prÃ©vient le biais des queues longues)
- Seuil de co-occurrence minimum : K (dÃ©faut = 10)
- Tokenization insensible Ã  la casse, regex `[a-z]+`

**Formule** :
$$\text{PMI}(x, y) = \log_{10}\left(\frac{P(x, y)}{P(x) \cdot P(y)}\right)$$

**RÃ©sultats principaux** :
- `('i', 'am')` PMI â‰ˆ 0,09 (phrase commune)
- `('romeo', 'juliet')` PMI â‰ˆ 1,8 (co-apparition rare)

**Livrables** :
- `outputs/pmi_filtered.csv`
- `proof/plan_pmi.txt`

---

### Partie C : Index inversÃ© et recherche boolÃ©enne

**TÃ¢che** : Construire un index consultable Ã  partir de documents synthÃ©tiques et exÃ©cuter des requÃªtes AND/OR.

**DÃ©finition de document** :
- 10 lignes consÃ©cutives = 1 document synthÃ©tique
- `doc_id = floor(line_number / 10)`
- Total : ~12 000 documents

**SchÃ©ma d'index** (Parquet) :
```
term: STRING
df: INT                           (document frequency)
postings: ARRAY<STRUCT>
  â”œâ”€â”€ doc_id: INT
  â””â”€â”€ tf: INT                     (term frequency)
```

**Exemples de requÃªtes** :
1. `love AND heart` â†’ 173 documents
2. `romeo AND juliet` â†’ 16 documents
3. `fair OR beautiful` â†’ 688 documents

**Logique de requÃªte** :
- AND : Intersection des listes de postings
- OR : Union des listes de postings
- Scoring : Somme des valeurs TF Ã— IDF

**Livrables** :
- `outputs/index_parquet/` (schÃ©ma indexÃ©)
- `outputs/queries_and_results.md` (3+ rÃ©sultats de requÃªtes)
- `proof/plan_retrieval.txt`

---

### Partie D : Ã‰tude de performance

**TÃ¢che** : Comparer les designs Pairs vs Stripes et optimiser `shuffle.partitions`.

**RÃ©sultats clÃ©s** :

| Configuration | DurÃ©e (s) | Bigrammes | Surcharge shuffle |
|---|---|---|---|
| 8 partitions | 2,73 | 286 728 | Haute (peu de parallÃ©lisme) |
| 16 partitions | 2,32 | 286 728 | Ã‰quilibrÃ© |
| **32 partitions** | **1,93** | **286 728** | ** Optimal** |
| 64 partitions | 2,31 | 286 728 | Surcharge d'ordonnancement |

**Recommandation** : `spark.sql.shuffle.partitions = 32` pour le dataset Shakespeare de 3,6 MB

**Livrables** :
- `outputs/performance_pairs_vs_stripes.csv`
- `outputs/performance_shuffle_partitions.csv`
- `outputs/performance_analysis.md`
- `proof/lab_metrics_log.csv` (mis Ã  jour avec mÃ©triques de shuffle)

---

## ğŸ“Š Preuves et mÃ©triques

### MÃ©triques enregistrÃ©es (lab_metrics_log.csv)

```csv
run_id,task,timestamp,files_read,input_size_mb,shuffle_read_mb,shuffle_write_mb,duration_sec,notes
3,bigram_pairs,2025-11-19T18:20:23Z,1,3.6,4.0,4.0,3.0,"Job 79: reduceByKey (Stage 117)"
4,bigram_stripes,2025-11-20T07:28:06Z,1,3.6,2.2,2.2,9.0,"Job 22: groupByKey (Stage 29)"
5,pmi_filtered,2025-11-20T08:07:38Z,1,3.6,3.7,3.7,3.0,"Calcul PMI"
6,inverted_index,2025-11-20T08:40:27Z,1,3.6,5.3,5.3,7.6,"Construction d'index avec Parquet"
7,boolean_retrieval,2025-11-20T09:16:16Z,5,1.9,0.0,0.0,0.9,"ExÃ©cution de requÃªtes (partition pruning)"
```

### InterprÃ©tation EXPLAIN FORMATTED

**Approche Pairs** :
```
== Physical Plan ==
TakeOrderedAndProject(limit=20, orderBy=[count DESC])
+- *(1) Scan ExistingRDD[word1, word2, count]
```

**InterprÃ©tation** :
-  AgrÃ©gation prÃ©coce : `reduceByKey` prÃ©-calcule les comptes avant shuffle
-  Pas de shuffle supplÃ©mentaire : RÃ©sultats dÃ©jÃ  agrÃ©gÃ©s
-  Sort + take(20) : AppliquÃ© localement
-  WholeStageCodegen (*) : Fusionne les opÃ©rations en un seul bytecode JVM

---

##  Concepts clÃ©s appris

### Traduction MapReduce â†’ Spark

| Pattern | MapReduce | Spark | Notes |
|---|---|---|---|
| **Combiner** | AgrÃ©gation locale avant shuffle | `reduceByKey` (intÃ©grÃ©) | Design Pairs en exploite ceci |
| **Groupage** | `groupByKey` | `groupByKey` (pas de combiner) | Design Stripes : shuffle complet |
| **Join** | BasÃ© sur hash | Broadcast (si petit) | Permet le partition pruning |
| **Sort** | Tri-fusion externe | Sort sensible au spill | ExÃ©cution de requÃªte adaptative |

### Optimisation de performance

1. **Partitionnement Shuffle**
   - Trop peu : Data skew, dÃ©passement mÃ©moire
   - Trop : Surcharge d'ordonnancement de tÃ¢ches
   - Optimum : 32 partitions pour 3,6 MB â†’ 1,93 s

2. **Compression Parquet**
   - Snappy : Bon Ã©quilibre (47% de rÃ©duction dans ce cas)
   - GZIP : Meilleur ratio (50%+) mais plus lent
   - Sans compression : Rapide mais fichiers plus gros

3. **Partition Pruning**
   - Filtres poussÃ©s : RÃ©duire les donnÃ©es lues Ã  la source
   - RequÃªte sur boolean_retrieval : 5 fichiers â†’ 1 fichier seulement

---

##  RÃ©sumÃ© des rÃ©sultats

### Top bigrammes (Pairs)
```
1. (i, am):        count=1832, rel_freq=0,0915
2. (my, lord):     count=1645, rel_freq=0,1341
3. (in, the):      count=1605, rel_freq=0,1511
4. (i, have):      count=1580, rel_freq=0,0789
5. (i, will):      count=1528, rel_freq=0,0763
```

### Exemples de paires PMI
```
PMI Ã©levÃ© (co-apparition rare) :
  ('romeo', 'juliet'): PMI â‰ˆ 1,8
  ('fair', 'beautiful'): PMI â‰ˆ 0,7

PMI faible (commun mais indÃ©pendant) :
  ('the', 'a'): PMI â‰ˆ 0,02
```

### Statistiques d'index inversÃ©
- **Taille** : 1,9 MB (Parquet, snappy)
- **Original** : 3,6 MB (texte)
- **Compression** : 47% de rÃ©duction
- **Latence de requÃªte** : <1 seconde

---

##  ReproductibilitÃ©

### VÃ©rification d'environnement

```python
import pyspark
print(f"PySpark: {pyspark.__version__}")      # 4.0.1

import java
print(f"Java: {java.lang.System.getProperty('java.version')}")  # 21.0.6

import sys
print(f"Python: {sys.version}")               # 3.10.19
```

### ExÃ©cuter depuis zÃ©ro

```bash
# Effacer les sorties et rÃ©exÃ©cuter
rm -rf outputs proof

# RÃ©exÃ©cuter le notebook
jupyter nbconvert --to notebook --inplace --execute BDA_Assignment02.ipynb

# VÃ©rifier les rÃ©sultats
ls -lh outputs/
cat proof/lab_metrics_log.csv
```

### Contraintes clÃ©s de reproductibilitÃ©

**AppliquÃ©es** :
- Chemins relatifs : `./data/shakespeare.txt` (pas `/mnt/c/...`)
- Seeds fixes (si nÃ©cessaire) : `sparkContext.randomSeed = 42`
- Timestamps UTC : Tous les timestamps au format ISO
- Tri dÃ©terministe : `ORDER BY + LIMIT`
- Encodage UTF-8 : Tous les I/O texte

---

## ProblÃ¨mes courants et solutions

### ProblÃ¨me 1 : FileNotFoundException

```python
# âœ— FAUX (chemin absolu)
df = spark.read.text("/mnt/c/Users/phams/Desktop/E5/BigData/Lab2/assignment/data/shakespeare.txt")

# âœ“ CORRECT (chemin relatif)
df = spark.read.text("./data/shakespeare.txt")
```

### ProblÃ¨me 2 : DÃ©passement de mÃ©moire (Stripes)

```python
# Stripes utilise groupByKey â†’ donnÃ©es complÃ¨tes en mÃ©moire
# Solution : Repartitionner avant groupage
rdd = rdd.repartition(64)  # Plus de partitions â†’ moins de donnÃ©es par tÃ¢che
```

### ProblÃ¨me 3 : Shuffle lent

```python
# VÃ©rifier les mÃ©triques Spark UI
# Si shuffle_write > input_size Ã— 2, investiguer le skew
# Solution : Utiliser du salt pour les clÃ©s de haute cardinalitÃ©
df = df.withColumn("salt", F.rand() * 10)
df = df.repartition(32, "key", "salt")
```

### ProblÃ¨me 4 : MÃ©triques manquantes dans lab_metrics_log.csv

```bash
# Ajouter manuellement Ã  partir de Spark UI (http://localhost:4040)
# Pour chaque job : onglet Stages â†’ chercher shuffle_read_mb, shuffle_write_mb
# Ajouter une ligne Ã  proof/lab_metrics_log.csv
```

---

##  RÃ©fÃ©rences

### MatÃ©riaux du cours
- **Chapitre 3** : Conception d'algorithmes MapReduce (Pairs, Stripes)
- **Chapitre 4** : Analyse de texte (FrÃ©quence, PMI, Indexation)

### Documentation Spark
- [EXPLAIN FORMATTED](https://spark.apache.org/docs/latest/sql-performance-tuning.html)
- [RDD et Streaming](https://spark.apache.org/docs/latest/rdd-programming-guide.html)
- [DataFrame API](https://spark.apache.org/docs/latest/api/python/)

### Outils
- **Spark UI** : `http://localhost:4040` (pendant l'exÃ©cution)
- **Jupyter Lab** : `http://localhost:8888`
- **Conda** : Gestion d'environnement isolÃ©

---

### Ã‰tapes de tÃ©lÃ©chargement

```bash
# 1. Ajouter tous les fichiers Ã  Git
cd Lab2/assignment
git add .

# 2. Commit avec message clair
git commit -m "BDA Assignment 02 : Analyse de texte avec Spark (Parties A-D complÃ¨tes)"

# 3. Push vers GitHub
git push origin main

# 4. Partager le lien du repo dans le formulaire Google
# https://github.com/<votre-nom-utilisateur>/BDA-Labs
```

---

##  RÃ©sultats d'apprentissage

AprÃ¨s avoir complÃ©tÃ© cet assignment, vous devriez comprendre :

1. **Patterns MapReduce** : Compromis Pairs vs Stripes pour l'agrÃ©gation
2. **Traduction Spark** : Ã‰quivalents RDD/DataFrame/SQL
3. **Analyse de texte** : FrÃ©quence, PMI, indexation inversÃ©e
4. **Tuning de performance** : Partitions shuffle, compression, partition pruning
5. **IngÃ©nierie de reproductibilitÃ©** : Environnements, chemins relatifs, enregistrement de mÃ©triques
6. **Optimisation basÃ©e sur preuves** : Plans EXPLAIN, mÃ©triques Spark UI

---

